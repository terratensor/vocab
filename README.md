# Vocab

Vocab — это инструмент для создания словаря из текстовых файлов. Он поддерживает токенизацию, фильтрацию знаков препинания, приведение к нижнему регистру, сортировку по частоте или алфавиту, а также обработку файлов в формате `.gz`.

В папке `vocab` содержаться сформированные с разными параметрами словари 50 книг ВП СССР в папке `./books`. 

Например, [vocab/vocab_alpha.txt](https://github.com/terratensor/vocab/blob/main/vocab/vocab_alpha.txt) содержит словарь КОБ, отсортированный по алфавиту.

## Установка

1. Убедитесь, что у вас установлен Go (версия 1.16 или выше).
2. Установите проект:

   ```bash
   go install github.com/terratensor/vocab/cmd/vocab@latest

## Использование

```bash
vocab -dir=/path/to/files -output=vocab.txt -sort=freq -lowercase=true -filter-punct=true
```

## Флаги
- `-dir`: Путь к директории с текстовыми файлами (по умолчанию: `./files`).

- `-output`: Имя выходного файла (по умолчанию: `vocab.txt`).

- `-sort`: Тип сортировки (`freq` для частоты, `alpha` для алфавитной сортировки).

- `-lowercase`: Приводить токены к нижнему регистру (по умолчанию: `false`).

- `-filter-punct`: Фильтровать знаки препинания (по умолчанию: `false`).

- `-max-goroutines`: Максимальное количество горутин (по умолчанию: количество процессоров).

- `-pprof`: Включить профилирование с помощью `pprof` (по умолчанию: `false`).

## Примеры

### Базовое использование

```bash
vocab -dir=./books -output=my_vocab.txt -sort=freq -lowercase=true
```

### Обработка `.gz` файлов
Программа автоматически распаковывает файлы с расширением `.gz` перед обработкой.

```bash
vocab -dir=./compressed_books -output=vocab.txt
```

### Логирование ошибок

Если при обработке файла возникает ошибка, программа:

1. Записывает ошибку в лог-файл vocab_errors/vocab_errors.log.

2. Копирует проблемный файл в папку vocab_errors.

Пример лога:

```bash 
2023/10/10 12:34:56 Error opening file ./books/broken_file.txt: file not found
```

### Профилирование с помощью `pprof`

Для анализа производительности программы можно включить профилирование:

```bash
vocab -dir=./books -output=vocab.txt -pprof=true
```
После запуска откройте браузер и перейдите по адресу: `http://localhost:6060/debug/pprof/`.

### Анализ данных:

- Используйте команду go tool pprof для анализа данных. Например:

   ```bash
   go tool pprof http://localhost:6060/debug/pprof/profile
   ```
- После запуска команды вы попадете в интерактивный режим pprof. Используйте команды:

   - top — показать самые ресурсоемкие функции.

   - list <функция> — показать код функции.

   - web — открыть визуализацию в браузере.

#### Пример анализа CPU:

```bash
go tool pprof http://localhost:6060/debug/pprof/profile
```

### Пример анализа памяти:

```bash
go tool pprof http://localhost:6060/debug/pprof/heap
```

### Профилирование горутин:

```bash
go tool pprof http://localhost:6060/debug/pprof/goroutine
```

## Лицензия
Этот проект распространяется под лицензией MIT. См. LICENSE.


## Что дальше?

#### 1. Тестирование:
 - Написать unit-тесты для пакета tokenizer.
 - Использовать go test для проверки корректности работы.

#### 2. CI/CD:
 - Настроить GitHub Actions для автоматического тестирования и сборки.

#### 3. Документация:

 - Добавить примеры использования в README.md.

 - Создать документацию с помощью godoc.

#### 4. Оптимизация:

 - Профилировать программу с помощью pprof для поиска узких мест.

#### 5. Расширение функционала:

 - Добавить поддержку других форматов файлов (например, PDF, DOCX).

 - Реализовать фильтрацию стоп-слов.

#### 6. Публикация:

 - Опубликовать пакет в Go Module Registry.

